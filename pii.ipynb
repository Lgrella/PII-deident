{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python -m spacy download en_core_web_sm\n",
    "#python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (0.15.1)\n",
      "Requirement already satisfied: stanza in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.10.1)\n",
      "Requirement already satisfied: pandas in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.2.3)\n",
      "Requirement already satisfied: torch in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (2.2.2)\n",
      "Requirement already satisfied: transformers in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (4.50.3)\n",
      "Requirement already satisfied: presidio-anonymizer in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (2.2.358)\n",
      "Requirement already satisfied: presidio_analyzer[transformers] in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (2.2.358)\n",
      "Requirement already satisfied: huggingface_hub in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from presidio_analyzer[transformers]->-r requirements.txt (line 1)) (0.30.1)\n",
      "Requirement already satisfied: phonenumbers<9.0.0,>=8.12 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from presidio_analyzer[transformers]->-r requirements.txt (line 1)) (8.13.55)\n",
      "Requirement already satisfied: pyyaml in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from presidio_analyzer[transformers]->-r requirements.txt (line 1)) (6.0.2)\n",
      "Requirement already satisfied: regex in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from presidio_analyzer[transformers]->-r requirements.txt (line 1)) (2024.11.6)\n",
      "Requirement already satisfied: spacy!=3.7.0,<4.0.0,>=3.4.4 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from presidio_analyzer[transformers]->-r requirements.txt (line 1)) (3.8.5)\n",
      "Collecting spacy_huggingface_pipelines (from presidio_analyzer[transformers]->-r requirements.txt (line 1))\n",
      "  Using cached spacy_huggingface_pipelines-0.0.4-py2.py3-none-any.whl.metadata (10.0 kB)\n",
      "Requirement already satisfied: tldextract in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from presidio_analyzer[transformers]->-r requirements.txt (line 1)) (5.1.3)\n",
      "Requirement already satisfied: boto3>=1.20.27 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (1.37.25)\n",
      "Requirement already satisfied: conllu<5.0.0,>=4.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (4.5.3)\n",
      "Requirement already satisfied: deprecated>=1.2.13 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (1.2.18)\n",
      "Requirement already satisfied: ftfy>=6.1.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (6.3.1)\n",
      "Requirement already satisfied: gdown>=4.4.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (5.2.0)\n",
      "Requirement already satisfied: langdetect>=1.0.9 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (1.0.9)\n",
      "Requirement already satisfied: lxml>=4.8.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (5.3.1)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (3.10.1)\n",
      "Requirement already satisfied: more-itertools>=8.13.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (10.6.0)\n",
      "Requirement already satisfied: mpld3>=0.3 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (0.5.10)\n",
      "Requirement already satisfied: pptree>=3.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (1.6.1)\n",
      "Requirement already satisfied: segtok>=1.5.11 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (1.5.11)\n",
      "Requirement already satisfied: sqlitedict>=2.0.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (2.1.0)\n",
      "Requirement already satisfied: tabulate>=0.8.10 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=4.63.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (0.4.0)\n",
      "Requirement already satisfied: wikipedia-api>=0.5.7 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (0.8.1)\n",
      "Requirement already satisfied: bioc<3.0.0,>=2.0.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from flair->-r requirements.txt (line 3)) (2.1)\n",
      "Requirement already satisfied: emoji in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from stanza->-r requirements.txt (line 4)) (2.14.1)\n",
      "Requirement already satisfied: numpy in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from stanza->-r requirements.txt (line 4)) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from stanza->-r requirements.txt (line 4)) (6.30.2)\n",
      "Requirement already satisfied: requests in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from stanza->-r requirements.txt (line 4)) (2.32.3)\n",
      "Requirement already satisfied: networkx in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from stanza->-r requirements.txt (line 4)) (3.4.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: filelock in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from torch->-r requirements.txt (line 6)) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from torch->-r requirements.txt (line 6)) (4.13.0)\n",
      "Requirement already satisfied: sympy in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from torch->-r requirements.txt (line 6)) (1.13.3)\n",
      "Requirement already satisfied: jinja2 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from torch->-r requirements.txt (line 6)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from torch->-r requirements.txt (line 6)) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (24.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: cryptography<44.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from presidio-anonymizer->-r requirements.txt (line 8)) (44.0.2)\n",
      "Requirement already satisfied: jsonlines>=1.2.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from bioc<3.0.0,>=2.0.0->flair->-r requirements.txt (line 3)) (4.0.0)\n",
      "Requirement already satisfied: intervaltree in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from bioc<3.0.0,>=2.0.0->flair->-r requirements.txt (line 3)) (3.1.0)\n",
      "Requirement already satisfied: docopt in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from bioc<3.0.0,>=2.0.0->flair->-r requirements.txt (line 3)) (0.6.2)\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.25 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from boto3>=1.20.27->flair->-r requirements.txt (line 3)) (1.37.25)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from boto3>=1.20.27->flair->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from boto3>=1.20.27->flair->-r requirements.txt (line 3)) (0.11.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from cryptography<44.1->presidio-anonymizer->-r requirements.txt (line 8)) (1.17.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from deprecated>=1.2.13->flair->-r requirements.txt (line 3)) (1.17.2)\n",
      "Requirement already satisfied: wcwidth in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from ftfy>=6.1.0->flair->-r requirements.txt (line 3)) (0.2.13)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from gdown>=4.4.0->flair->-r requirements.txt (line 3)) (4.13.3)\n",
      "Requirement already satisfied: six in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from langdetect>=1.0.9->flair->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair->-r requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair->-r requirements.txt (line 3)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair->-r requirements.txt (line 3)) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair->-r requirements.txt (line 3)) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair->-r requirements.txt (line 3)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from matplotlib>=2.2.3->flair->-r requirements.txt (line 3)) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from scikit-learn>=1.0.2->flair->-r requirements.txt (line 3)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from scikit-learn>=1.0.2->flair->-r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from scikit-learn>=1.0.2->flair->-r requirements.txt (line 3)) (3.6.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (0.15.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (2.11.1)\n",
      "Requirement already satisfied: setuptools in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (75.8.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (3.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from requests->stanza->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from requests->stanza->-r requirements.txt (line 4)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from requests->stanza->-r requirements.txt (line 4)) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from requests->stanza->-r requirements.txt (line 4)) (2025.1.31)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from transformers[sentencepiece]<5.0.0,>=4.25.0->flair->-r requirements.txt (line 3)) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from jinja2->torch->-r requirements.txt (line 6)) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from sympy->torch->-r requirements.txt (line 6)) (1.3.0)\n",
      "Requirement already satisfied: requests-file>=1.4 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from tldextract->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (2.1.0)\n",
      "Requirement already satisfied: pycparser in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from cffi>=1.12->cryptography<44.1->presidio-anonymizer->-r requirements.txt (line 8)) (2.22)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from jsonlines>=1.2.0->bioc<3.0.0,>=2.0.0->flair->-r requirements.txt (line 3)) (25.3.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (2.33.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (0.4.0)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (0.1.5)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->-r requirements.txt (line 3)) (1.6.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (7.1.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from beautifulsoup4->gdown>=4.4.0->flair->-r requirements.txt (line 3)) (2.6)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from intervaltree->bioc<3.0.0,>=2.0.0->flair->-r requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from requests[socks]->gdown>=4.4.0->flair->-r requirements.txt (line 3)) (1.7.1)\n",
      "Requirement already satisfied: psutil in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from accelerate>=0.26.0->transformers[sentencepiece,torch]<5.0,>=4.1->transformer-smaller-training-vocab>=0.2.3->flair->-r requirements.txt (line 3)) (5.9.0)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/lillygrella/anaconda3/envs/pii2/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy!=3.7.0,<4.0.0,>=3.4.4->presidio_analyzer[transformers]->-r requirements.txt (line 1)) (0.1.2)\n",
      "Using cached spacy_huggingface_pipelines-0.0.4-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: spacy_huggingface_pipelines\n",
      "Successfully installed spacy_huggingface_pipelines-0.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 424kB [00:00, 79.1MB/s]                    \n",
      "2025-04-02 13:20:27 INFO: Downloaded file to /Users/lillygrella/stanza_resources/resources.json\n",
      "2025-04-02 13:20:27 INFO: Downloading default packages for language: en (English) ...\n",
      "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/default.zip: 100%|██████████| 526M/526M [00:08<00:00, 65.0MB/s] \n",
      "2025-04-02 13:20:38 INFO: Downloaded file to /Users/lillygrella/stanza_resources/en/default.zip\n",
      "2025-04-02 13:20:44 INFO: Finished downloading models and saved to /Users/lillygrella/stanza_resources\n"
     ]
    }
   ],
   "source": [
    "import stanza\n",
    "stanza.download(\"en\") # where en is the language code of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformers_mname = \"StanfordAIMI/stanford-deidentifier-base\"\n",
    "transformers_mname = \"obi/deid_roberta_i2b2\"\n",
    "#transformers_mname = \"flair/ner-english-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 10 files: 100%|██████████| 10/10 [00:20<00:00,  2.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForTokenClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-23): 24 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=1024, out_features=45, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "transformers_model = transformers_mname\n",
    "\n",
    "snapshot_download(repo_id=transformers_model)\n",
    "\n",
    "# Instantiate to make sure it's downloaded during installation and not runtime\n",
    "AutoTokenizer.from_pretrained(transformers_model)\n",
    "AutoModelForTokenClassification.from_pretrained(transformers_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/lillygrella/.flair/models/ner-english-large'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:409\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/requests/models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/ner-english-large/resolve/main/pytorch_model.bin",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/flair/file_utils.py:165\u001b[39m, in \u001b[36mhf_download\u001b[39m\u001b[34m(model_name)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mflair\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflair\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__version__\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflair\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache_root\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError:\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# output information\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/huggingface_hub/file_download.py:961\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    960\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m961\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m    963\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/huggingface_hub/file_download.py:1068\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1067\u001b[39m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1068\u001b[39m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/huggingface_hub/file_download.py:1596\u001b[39m, in \u001b[36m_raise_on_head_call_error\u001b[39m\u001b[34m(head_call_error, force_download, local_files_only)\u001b[39m\n\u001b[32m   1591\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, (RepositoryNotFoundError, GatedRepoError)) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1592\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(head_call_error, HfHubHTTPError) \u001b[38;5;129;01mand\u001b[39;00m head_call_error.response.status_code == \u001b[32m401\u001b[39m\n\u001b[32m   1593\u001b[39m ):\n\u001b[32m   1594\u001b[39m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[32m   1595\u001b[39m     \u001b[38;5;66;03m# Unauthorized => likely a token issue => let's raise the actual error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1596\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[32m   1597\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1598\u001b[39m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/huggingface_hub/file_download.py:1484\u001b[39m, in \u001b[36m_get_metadata_or_catch_error\u001b[39m\u001b[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[39m\n\u001b[32m   1483\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1484\u001b[39m     metadata = \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1485\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\n\u001b[32m   1486\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1487\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/huggingface_hub/file_download.py:1401\u001b[39m, in \u001b[36mget_hf_file_metadata\u001b[39m\u001b[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[39m\n\u001b[32m   1400\u001b[39m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1401\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHEAD\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1410\u001b[39m hf_raise_for_status(r)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/huggingface_hub/file_download.py:285\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     response = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[32m    293\u001b[39m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/huggingface_hub/file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    308\u001b[39m response = get_session().request(method=method, url=url, **params)\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:459\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    450\u001b[39m     message = (\n\u001b[32m    451\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Client Error.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    452\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    457\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m https://huggingface.co/docs/huggingface_hub/authentication\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    458\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m459\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m400\u001b[39m:\n",
      "\u001b[31mRepositoryNotFoundError\u001b[39m: 401 Client Error. (Request ID: Root=1-67ed7441-7cccf4c10bf6deb9526a730b;66ddebb2-1126-4bb8-a07a-e3cf70713388)\n\nRepository Not Found for url: https://huggingface.co/ner-english-large/resolve/main/pytorch_model.bin.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mflair\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SequenceTagger\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Download the 'ner-english-large' model manually\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m tagger = \u001b[43mSequenceTagger\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mner-english-large\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/flair/models/sequence_tagger_model.py:947\u001b[39m, in \u001b[36mSequenceTagger.load\u001b[39m\u001b[34m(cls, model_path)\u001b[39m\n\u001b[32m    943\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, model_path: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]) -> \u001b[33m\"\u001b[39m\u001b[33mSequenceTagger\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    945\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cast\n\u001b[32m--> \u001b[39m\u001b[32m947\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mSequenceTagger\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/flair/nn/model.py:583\u001b[39m, in \u001b[36mClassifier.load\u001b[39m\u001b[34m(cls, model_path)\u001b[39m\n\u001b[32m    579\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    580\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mcls\u001b[39m, model_path: Union[\u001b[38;5;28mstr\u001b[39m, Path, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]) -> \u001b[33m\"\u001b[39m\u001b[33mClassifier\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    581\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cast\n\u001b[32m--> \u001b[39m\u001b[32m583\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[33m\"\u001b[39m\u001b[33mClassifier\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/flair/nn/model.py:192\u001b[39m, in \u001b[36mModel.load\u001b[39m\u001b[34m(cls, model_path)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# if this class is not abstract, fetch the model and load it\u001b[39;00m\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model_path, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m         model_file = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m         state = load_torch_state(model_file)\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/flair/models/sequence_tagger_model.py:789\u001b[39m, in \u001b[36mSequenceTagger._fetch_model\u001b[39m\u001b[34m(model_name)\u001b[39m\n\u001b[32m    780\u001b[39m         log.warning(\n\u001b[32m    781\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mHunFlair (version 1) is deprecated. Consider using HunFlair2 for improved extraction performance: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    782\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mClassifier.load(\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhunflair2\u001b[39m\u001b[33m'\u001b[39m\u001b[33m).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    783\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSee https://github.com/flairNLP/flair/blob/master/resources/docs/HUNFLAIR2.md for further \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    784\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33minformation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    785\u001b[39m         )\n\u001b[32m    787\u001b[39m \u001b[38;5;66;03m# for all other cases (not local file or special download location), use HF model hub\u001b[39;00m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     model_path = \u001b[43mhf_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model_path\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/site-packages/flair/file_utils.py:175\u001b[39m, in \u001b[36mhf_download\u001b[39m\u001b[34m(model_name)\u001b[39m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hf_hub_download(\n\u001b[32m    166\u001b[39m         repo_id=model_name,\n\u001b[32m    167\u001b[39m         filename=hf_model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    171\u001b[39m         cache_dir=flair.cache_root / \u001b[33m\"\u001b[39m\u001b[33mmodels\u001b[39m\u001b[33m\"\u001b[39m / model_folder,\n\u001b[32m    172\u001b[39m     )\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError:\n\u001b[32m    174\u001b[39m     \u001b[38;5;66;03m# output information\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflair\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcache_root\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_folder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrmdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# remove folder again if not valid\u001b[39;00m\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/pii2/lib/python3.12/pathlib.py:1351\u001b[39m, in \u001b[36mPath.rmdir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrmdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1348\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1349\u001b[39m \u001b[33;03m    Remove this directory.  The directory must be empty.\u001b[39;00m\n\u001b[32m   1350\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1351\u001b[39m     \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrmdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/lillygrella/.flair/models/ner-english-large'"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "\n",
    "# Download the 'ner-english-large' model manually\n",
    "tagger = SequenceTagger.load(\"ner-english-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from presidio_helpers import (\n",
    "    get_supported_entities,\n",
    "    analyze,\n",
    "    anonymize,\n",
    "    analyzer_engine,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_model_package = \"spaCy\"\n",
    "st_model = \"en_core_web_lg\"\n",
    "\n",
    "#st_model_package = \"obi\"\n",
    "#st_model = \"deid_roberta_i2b2\"\n",
    "\n",
    "st_threshold = .3\n",
    "\n",
    "#read in docx\n",
    "from docx import Document\n",
    "with open(\"worddoctest.docx\", \"rb\") as f:\n",
    "    demo_text = Document(f)\n",
    "    demo_text = [p.text for p in demo_text.paragraphs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few example sentences we currently support:\n",
      "\n",
      "Hello, my name is Lilly Grella and I live in North carolina.\n",
      "My credit card number is 2840-1285-1243-1345 and my crypto wallet id is 16Yeky6GMjeNkAiNcBY7ZhrLoMSgg1BoyZ.\n",
      "\n",
      "On September 18 I visited microsoft.com and sent an email to tlmgrella13@gmail.com,  from the IP 192.168.0.1.\n",
      "\n",
      "My passport: 123445678 and my phone number: (757) 532-1139.\n",
      "\n",
      "This is a valid International Bank Account Number: IL150120690000003111111 . Can you please check the status on bank account 954567876544?\n",
      "\n",
      "KC’s social security number is 112-33-4455.  Her driver license? it is 1234567A.\n"
     ]
    }
   ],
   "source": [
    "final_text = \"\\n\".join(demo_text)\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_params = (st_model_package, st_model)\n",
    "default_entities = ['IN_PASSPORT', 'FACILITY', 'MEDICAL_LICENSE', 'US_SSN', 'UK_NINO', 'EMAIL_ADDRESS', 'PERSON', 'IN_AADHAAR', 'IP_ADDRESS', 'CRYPTO', 'NRP', 'IN_VOTER', 'DATE_TIME', 'AU_ACN', 'US_PASSPORT', 'UK_NHS', 'PHONE_NUMBER', 'IBAN_CODE', 'URL', 'IN_VEHICLE_REGISTRATION', 'AU_TFN', 'US_BANK_NUMBER', 'SG_NRIC_FIN', 'IN_PAN', 'AU_MEDICARE', 'US_DRIVER_LICENSE', 'CREDIT_CARD', 'US_ITIN', 'AU_ABN', 'LOCATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = analyzer_engine(st_model_package, st_model)\n",
    "st_entities=list(get_supported_entities(*analyzer_params)),\n",
    "st_analyze_results = analyze(st_model_package, st_model, text=final_text,\n",
    "                             entities=default_entities,\n",
    "                             language=\"en\",\n",
    "                             score_threshold=st_threshold,\n",
    "                             return_decision_process=True,\n",
    "    #allow_list=st_allow_list,\n",
    "    #deny_list=st_deny_list,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[type: CRYPTO, start: 189, end: 223, score: 1.0, type: EMAIL_ADDRESS, start: 287, end: 308, score: 1.0, type: IBAN_CODE, start: 449, end: 472, score: 1.0, type: IP_ADDRESS, start: 323, end: 334, score: 0.95, type: LOCATION, start: 101, end: 115, score: 0.85, type: DATE_TIME, start: 229, end: 241, score: 0.85, type: DATE_TIME, start: 316, end: 334, score: 0.85, type: DATE_TIME, start: 350, end: 359, score: 0.85, type: LOCATION, start: 538, end: 540, score: 0.85, type: US_SSN, start: 569, end: 580, score: 0.85, type: PHONE_NUMBER, start: 381, end: 395, score: 0.75, type: US_DRIVER_LICENSE, start: 609, end: 617, score: 0.6499999999999999, type: URL, start: 252, end: 265, score: 0.5, type: URL, start: 299, end: 308, score: 0.5, type: US_PASSPORT, start: 350, end: 359, score: 0.4, type: US_BANK_NUMBER, start: 523, end: 535, score: 0.4]\n"
     ]
    }
   ],
   "source": [
    "print(st_analyze_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_anonymize_results = anonymize(\n",
    "    text=final_text,\n",
    "    operator=\"replace\",\n",
    "    mask_char=\"-\",\n",
    "    number_of_chars=20,\n",
    "    encrypt_key=1234567,\n",
    "    analyze_results=st_analyze_results,\n",
    ")\n",
    "#keep only the anonymized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are a few example sentences we currently support:\n",
      "\n",
      "Hello, my name is Lilly Grella and I live in <LOCATION>.\n",
      "My credit card number is 2840-1285-1243-1345 and my crypto wallet id is <CRYPTO>.\n",
      "\n",
      "On <DATE_TIME> I visited <URL> and sent an email to <EMAIL_ADDRESS>,  from <DATE_TIME>.\n",
      "\n",
      "My passport: <DATE_TIME> and my phone number: <PHONE_NUMBER>.\n",
      "\n",
      "This is a valid International Bank Account Number: <IBAN_CODE> . Can you please check the status on bank account <US_BANK_NUMBER>?\n",
      "\n",
      "<LOCATION>’s social security number is <US_SSN>.  Her driver license? it is <US_DRIVER_LICENSE>.\n"
     ]
    }
   ],
   "source": [
    "print(st_anonymize_results.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Entity type                                Text  Start  End  \\\n",
      "0              CRYPTO  16Yeky6GMjeNkAiNcBY7ZhrLoMSgg1BoyZ    189  223   \n",
      "1       EMAIL_ADDRESS               tlmgrella13@gmail.com    287  308   \n",
      "2           IBAN_CODE             IL150120690000003111111    449  472   \n",
      "3          IP_ADDRESS                         192.168.0.1    323  334   \n",
      "4            LOCATION                      North carolina    101  115   \n",
      "5           DATE_TIME                        September 18    229  241   \n",
      "6           DATE_TIME                  the IP 192.168.0.1    316  334   \n",
      "7           DATE_TIME                           123445678    350  359   \n",
      "8            LOCATION                                  KC    538  540   \n",
      "9              US_SSN                         112-33-4455    569  580   \n",
      "10       PHONE_NUMBER                      (757) 532-1139    381  395   \n",
      "11  US_DRIVER_LICENSE                            1234567A    609  617   \n",
      "12                URL                       microsoft.com    252  265   \n",
      "13                URL                           gmail.com    299  308   \n",
      "14        US_PASSPORT                           123445678    350  359   \n",
      "15     US_BANK_NUMBER                        954567876544    523  535   \n",
      "\n",
      "    Confidence            recognizer                          pattern_name  \\\n",
      "0         1.00      CryptoRecognizer                       Crypto (Medium)   \n",
      "1         1.00       EmailRecognizer                        Email (Medium)   \n",
      "2         1.00        IbanRecognizer                          IBAN Generic   \n",
      "3         0.95          IpRecognizer                                  IPv4   \n",
      "4         0.85       SpacyRecognizer                                  None   \n",
      "5         0.85       SpacyRecognizer                                  None   \n",
      "6         0.85       SpacyRecognizer                                  None   \n",
      "7         0.85       SpacyRecognizer                                  None   \n",
      "8         0.85       SpacyRecognizer                                  None   \n",
      "9         0.85       UsSsnRecognizer                         SSN5 (medium)   \n",
      "10        0.75       PhoneRecognizer                                  None   \n",
      "11        0.65   UsLicenseRecognizer  Driver License - Alphanumeric (weak)   \n",
      "12        0.50         UrlRecognizer                        Non schema URL   \n",
      "13        0.50         UrlRecognizer                        Non schema URL   \n",
      "14        0.40  UsPassportRecognizer                  Passport (very weak)   \n",
      "15        0.40      UsBankRecognizer                   Bank Account (weak)   \n",
      "\n",
      "                                              pattern  original_score  score  \\\n",
      "0                  (bc1|[13])[a-zA-HJ-NP-Z0-9]{25,59}            0.50   1.00   \n",
      "1   \\b((([!#$%&'*+\\-/=?^_`{|}~\\w])|([!#$%&'*+\\-/=?...            0.50   1.00   \n",
      "2   \\b([A-Z]{2}[ \\-]?[0-9]{2})(?=(?:[ \\-]?[A-Z0-9]...            0.50   1.00   \n",
      "3   \\b(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\\.(?...            0.60   0.95   \n",
      "4                                                None            0.85   0.85   \n",
      "5                                                None            0.85   0.85   \n",
      "6                                                None            0.85   0.85   \n",
      "7                                                None            0.85   0.85   \n",
      "8                                                None            0.85   0.85   \n",
      "9        \\b([0-9]{3})[- .]([0-9]{2})[- .]([0-9]{4})\\b            0.50   0.85   \n",
      "10                                               None            0.40   0.75   \n",
      "11  \\b([A-Z][0-9]{3,6}|[A-Z][0-9]{5,9}|[A-Z][0-9]{...            0.30   0.65   \n",
      "12  (?i)((www\\d{0,3}[.])?[a-z0-9.\\-]+[.](?:(?:com)...            0.50   0.50   \n",
      "13  (?i)((www\\d{0,3}[.])?[a-z0-9.\\-]+[.](?:(?:com)...            0.50   0.50   \n",
      "14                                     (\\b[0-9]{9}\\b)            0.05   0.40   \n",
      "15                                    \\b[0-9]{8,17}\\b            0.05   0.40   \n",
      "\n",
      "                                  textual_explanation  \\\n",
      "0   Detected by `CryptoRecognizer` using pattern `...   \n",
      "1   Detected by `EmailRecognizer` using pattern `E...   \n",
      "2   Detected by `IbanRecognizer` using pattern `IB...   \n",
      "3     Detected by `IpRecognizer` using pattern `IPv4`   \n",
      "4   Identified as LOCATION by Spacy's Named Entity...   \n",
      "5   Identified as DATE_TIME by Spacy's Named Entit...   \n",
      "6   Identified as DATE_TIME by Spacy's Named Entit...   \n",
      "7   Identified as DATE_TIME by Spacy's Named Entit...   \n",
      "8   Identified as LOCATION by Spacy's Named Entity...   \n",
      "9   Detected by `UsSsnRecognizer` using pattern `S...   \n",
      "10  Recognized as US region phone number, using Ph...   \n",
      "11  Detected by `UsLicenseRecognizer` using patter...   \n",
      "12  Detected by `UrlRecognizer` using pattern `Non...   \n",
      "13  Detected by `UrlRecognizer` using pattern `Non...   \n",
      "14  Detected by `UsPassportRecognizer` using patte...   \n",
      "15  Detected by `UsBankRecognizer` using pattern `...   \n",
      "\n",
      "    score_context_improvement supportive_context_word validation_result  \\\n",
      "0                        0.50                  wallet              True   \n",
      "1                        0.50                   email              True   \n",
      "2                        0.50                    bank              True   \n",
      "3                        0.35                      ip              None   \n",
      "4                        0.00                                      None   \n",
      "5                        0.00                                      None   \n",
      "6                        0.00                                      None   \n",
      "7                        0.00                                      None   \n",
      "8                        0.00                                      None   \n",
      "9                        0.35                  social              None   \n",
      "10                       0.35                   phone              None   \n",
      "11                       0.35                  driver              None   \n",
      "12                       0.00                                      None   \n",
      "13                       0.00                                      None   \n",
      "14                       0.35                passport              None   \n",
      "15                       0.35                   check              None   \n",
      "\n",
      "    regex_flags  \n",
      "0          26.0  \n",
      "1          26.0  \n",
      "2          26.0  \n",
      "3          26.0  \n",
      "4           NaN  \n",
      "5           NaN  \n",
      "6           NaN  \n",
      "7           NaN  \n",
      "8           NaN  \n",
      "9          26.0  \n",
      "10          NaN  \n",
      "11         26.0  \n",
      "12         26.0  \n",
      "13         26.0  \n",
      "14         26.0  \n",
      "15         26.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "return_decision_process = True\n",
    "if st_analyze_results:\n",
    "    df = pd.DataFrame.from_records([r.to_dict() for r in st_analyze_results])\n",
    "    df[\"text\"] = [final_text[res.start : res.end] for res in st_analyze_results]\n",
    "\n",
    "    df_subset = df[[\"entity_type\", \"text\", \"start\", \"end\", \"score\"]].rename(\n",
    "        {\n",
    "            \"entity_type\": \"Entity type\",\n",
    "            \"text\": \"Text\",\n",
    "            \"start\": \"Start\",\n",
    "            \"end\": \"End\",\n",
    "            \"score\": \"Confidence\",\n",
    "        },\n",
    "        axis=1,\n",
    "    )\n",
    "    df_subset[\"Text\"] = [final_text[res.start : res.end] for res in st_analyze_results]\n",
    "    if return_decision_process:\n",
    "        analysis_explanation_df = pd.DataFrame.from_records(\n",
    "            [r.analysis_explanation.to_dict() for r in st_analyze_results]\n",
    "        )\n",
    "        df_subset = pd.concat([df_subset, analysis_explanation_df], axis=1)\n",
    "    print(df_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymized text has been written to anonymized_output.docx\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "\n",
    "# Function to write anonymized content to a new docx file\n",
    "def write_to_docx(anonymized_text, output_file_path):\n",
    "    doc = Document()\n",
    "    doc.add_paragraph(st_anonymize_results.text)  # Add anonymized text as a paragraph\n",
    "    doc.save(output_file_path)  # Save the document\n",
    "\n",
    "# Assuming st_anonymize_results contains the anonymized text (as a string)\n",
    "# For example, if anonymized text is a string like this:\n",
    "anonymized_text = st_anonymize_results\n",
    "\n",
    "# Now write this anonymized text to a new .docx file\n",
    "write_to_docx(anonymized_text, \"anonymized_output.docx\")\n",
    "\n",
    "print(\"Anonymized text has been written to anonymized_output.docx\")\n",
    "\n",
    "#output results to csv\n",
    "df_subset.to_csv(\"results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pii2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
